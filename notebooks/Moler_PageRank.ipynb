{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Personalized Pagerank Implementation (Moler PageRank)\n",
    "I needed a fast PageRank for Wikisim project, it has to be fast enough that can run in real time on relatively small graphs. I started from optimizing the networkx, however, I found a very nice algorithm by **Cleve Mole** which takes the full advantage of sparse matrix operations. \n",
    "I implemented two versions of the algorithm in Python, both inspired  by the sparse fast solutions given in [**Cleve Moler**](https://en.wikipedia.org/wiki/Cleve_Moler)'s book, [*Experiments with MATLAB*](http://www.mathworks.com/moler/index_ncm.html). The power method is much faster with enough precision for our task. Our benchmarsk shows that this implementation is **faster than both Networkx and iGraph** implementationa magnititude of times.\n",
    "\n",
    "## Personalized Pagerank\n",
    "I modified the algorithm a little bit to be able to calculate **personalized Pagerank** as well. \n",
    "\n",
    "## Input Format\n",
    "The input is a 2d array, each row of the array is an edge of the graph $[[a,b], [c,d]]$, $a$ and $b$ are the node numbers. The **personalization vector** is probability distribution over the nodes, a.k.a **teleporting vector**.\n",
    "\n",
    "## Comparison with Popular Python Implementations: Networkx and iGraph\n",
    "Both of the implementation (Exact Solution and PowerMethod) are much faster than their correspondent method in NetworkX. \n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pagerank.py\n",
    "\"\"\"Two \"fast\" implementations of PageRank.\n",
    "\n",
    "Pythom implementations of Matlab original in:\n",
    "Cleve Moler, Experiments with MATLAB.\n",
    "\"\"\"\n",
    "# uncomment\n",
    "from __future__ import division\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.sparse as sprs\n",
    "import scipy.spatial\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "__author__ = \"Armin Sajadi\"\n",
    "__copyright__ = \"Copyright 215, The Wikisim Project\"\n",
    "__credits__ = [\"Armin Sajadi\"]\n",
    "__license__ = \"GPL\"\n",
    "__version__ = \"1.0.1\"\n",
    "__maintainer__ = \"Armin Sajadi\"\n",
    "__email__ = \"sajadi@cs.dal.ca\"\n",
    "__status__ = \"Development\"\n",
    "\n",
    "\n",
    "def moler_pagerank(G, p=damping_factor,\n",
    "                          personalize=None, reverse=False):\n",
    "    \"\"\" Calculates pagerank given a csr graph\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "\n",
    "    G: a csr graph.\n",
    "    p: damping factor\n",
    "    personlize: if not None, should be an array with the size of the nodes\n",
    "                containing probability distributions.\n",
    "                It will be normalized automatically\n",
    "    reverse: If true, returns the reversed-pagerank\n",
    "\n",
    "    outputs\n",
    "    -------\n",
    "\n",
    "    Pagerank Scores for the nodes\n",
    "\n",
    "    \"\"\"\n",
    "    # In Moler's algorithm, $G_{ij}$ represents the existences of an edge\n",
    "    # from node $j$ to $i$, while we have assumed the opposite!\n",
    "    if not reverse:\n",
    "        G = G.T\n",
    "\n",
    "    n, _ = G.shape\n",
    "    c = sp.asarray(G.sum(axis=0)).reshape(-1)\n",
    "\n",
    "    k = c.nonzero()[0]\n",
    "\n",
    "    D = sprs.csr_matrix((1/c[k], (k, k)), shape=(n, n))\n",
    "\n",
    "    if personalize is None:\n",
    "        personalize = sp.ones(n)\n",
    "    personalize = personalize.reshape(n, 1)\n",
    "    e = (personalize/personalize.sum())*n\n",
    "\n",
    "    I = sprs.eye(n)\n",
    "    x = sprs.linalg.spsolve((I - p*G.dot(D)), e)\n",
    "\n",
    "    x = x / x.sum()\n",
    "    return x\n",
    "\n",
    "\n",
    "def moler_pagerank_power(G, p=damping_factor, max_iter=100,\n",
    "                                tol=1e-06, personalize=None, reverse=False):\n",
    "    \"\"\" Calculates pagerank given a csr graph\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    G: a csr graph.\n",
    "    p: damping factor\n",
    "    max_iter: maximum number of iterations\n",
    "    personlize: if not None, should be an array with the size of the nodes\n",
    "                containing probability distributions.\n",
    "                It will be normalized automatically.\n",
    "    reverse: If true, returns the reversed-pagerank\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Pagerank Scores for the nodes\n",
    "\n",
    "    \"\"\"\n",
    "    # In Moler's algorithm, $G_{ij}$ represents the existences of an edge\n",
    "    # from node $j$ to $i$, while we have assumed the opposite!\n",
    "    if not reverse:\n",
    "        G = G.T\n",
    "\n",
    "    n, _ = G.shape\n",
    "    c = sp.asarray(G.sum(axis=0)).reshape(-1)\n",
    "\n",
    "    k = c.nonzero()[0]\n",
    "\n",
    "    D = sprs.csr_matrix((1/c[k], (k, k)), shape=(n, n))\n",
    "\n",
    "    if personalize is None:\n",
    "        personalize = sp.ones(n)\n",
    "    personalize = personalize.reshape(n, 1)\n",
    "    e = (personalize / personalize.sum())*n\n",
    "\n",
    "    z = (((1-p) * (c != 0) + (c == 0)) / n)[sp.newaxis, :]\n",
    "    G = p * G.dot(D)\n",
    "\n",
    "    x = e / n\n",
    "    oldx = sp.zeros((n, 1))\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    while sp.linalg.norm(x-oldx) > tol:\n",
    "        oldx = x\n",
    "        x = G.dot(x) + e.dot(z.dot(x))\n",
    "        iteration += 1\n",
    "        if iteration >= max_iter:\n",
    "            break\n",
    "    x = x / sum(x)\n",
    "\n",
    "    return x.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "nxG = gnp_random_graph(n, , seed=None, directed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NetworkXError",
     "evalue": "Graph has no nodes or edges",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f37004c3c467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcustomization_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcustomization_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomization_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_scipy_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnxG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagerank_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnxG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersonalization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustomization_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/general/lib/python3.7/site-packages/networkx/convert_matrix.py\u001b[0m in \u001b[0;36mto_scipy_sparse_matrix\u001b[0;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0mnlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnlen\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Graph has no nodes or edges\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNetworkXError\u001b[0m: Graph has no nodes or edges"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import networkx as nx\n",
    "\n",
    "#sp.set_printoptions(precision=4)\n",
    "n=0\n",
    "m=0\n",
    "nxG = nx.gnm_random_graph(n=n, m=m, directed=True)\n",
    "for e in nxG.edges():\n",
    "     nxG[e[0]][e[1]]['weight']=sp.rand()\n",
    "customization_vector = sp.random.random(n)   \n",
    "customization_dict = dict(enumerate(customization_vector.reshape(-1)))\n",
    "A=nx.to_scipy_sparse_matrix(nxG)        \n",
    "alpha = (0.5) * sp.random.random_sample() + 0.5\n",
    "pr = nx.pagerank_numpy(nxG, alpha=alpha, personalization = customization_dict) \n",
    "row, col = A.nonzero()\n",
    "print(\"n=\", n)\n",
    "print(\"rows =\", row)\n",
    "print(\"col =\", col)\n",
    "print(\"data =\", sp.array2string(A.data, precision=4, separator=','))\n",
    "print (\"alpha = %.2f\" % (alpha, ))\n",
    "# print (\"custom_vector =\", sp.array2string(customization_vector, precision=4, separator=','))\n",
    "# print (\"pagerank =\", sp.array2string(sp.array(list(pr.values())), precision=4, separator=','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "rows = [0 0 1 1 1 2 2 3 4 4]\n",
    "col = [1 3 0 2 4 3 4 1 0 1]\n",
    "data = [0.816 ,0.0907,0.8684,0.4435,0.2637,0.6541,0.8442,0.6107,0.06  ,0.3243]\n",
    "alpha = 0.51\n",
    "A = sp.csr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(dict_values([0.3251974433833041, 0.3357826557854313, 0.08176181929591639, 0.04711915559561643, 0.2101389259397318]),\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "rows = [0 0 1 1 1 2 2 3 4 4]\n",
    "col = [1 3 0 2 4 3 4 1 0 1]\n",
    "data = [0.816 ,0.0907,0.8684,0.4435,0.2637,0.6541,0.8442,0.6107,0.06  ,0.3243]\n",
    "alpha = 0.51\n",
    "\n",
    "\n",
    "\n",
    "n = 10\n",
    "rows = [1 1 1 2 3 3 4 4 4 5 6 6 7 7 7 8 8 9 9 9]\n",
    "col = [4 6 8 5 4 9 6 7 8 8 2 7 0 2 9 0 7 1 3 5]\n",
    "data = [0.2839,0.2941,0.9678,0.1996,0.3949,0.6571,0.2927,0.8644,0.614 ,0.9861,\n",
    " 0.3228,0.5462,0.3262,0.4311,0.0764,0.1596,0.7978,0.9371,0.0692,0.4061]\n",
    "alpha = 0.58\n",
    "\n",
    "\n",
    "rows = [2]\n",
    "col = [4]\n",
    "data = [0.5441]\n",
    "alpha = 0.81\n",
    "\n",
    "n=5\n",
    "rows = []\n",
    "col = []\n",
    "data = []\n",
    "alpha = 0.70\n",
    "\n",
    "n=0\n",
    "rows = []\n",
    "col = []\n",
    "data = []\n",
    "alpha = 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxG.get_edge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../test/pagerank_test.py\n",
    "\n",
    "import networkx as nx\n",
    "import random\n",
    "import timeit\n",
    "import numpy as np\n",
    "import igraph\n",
    "from numpy.testing import assert_array_almost_equal\n",
    "\n",
    "import os\n",
    "import sys\n",
    "current = os.path.dirname(os.path.realpath(__file__))\n",
    "src_path = os.path.join(current, '..')\n",
    "sys.path.insert(0,src_path)\n",
    "\n",
    "from src.pagerank import *\n",
    "\n",
    "def get_random_graph(min_size=100, max_size=300, min_sparsity = 0.1, max_sparsity = 0.5):\n",
    "    ''' Creates a random graph and a teleport vector and output them in different formats for different algorithms\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    \n",
    "    min_size and max_size: The size of the graph will be a random number in the range of (min_size, max_size)\n",
    "    min_sparsity and max_sparsity: The sparcity of the graph will be a random number in the range of (min_sparsity, max_sparsity)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    nxG: A random Graph for NetworkX\n",
    "    A: The equivallent csr Adjacency matrix, for our moler_pagerank_times\n",
    "    iG: The equivallent iGraph\n",
    "    customization_vector: Personalization probabily vector\n",
    "    customization_dict: Personalization probabily vector, in the form of a dictionary for NetworkX\n",
    "    \n",
    "    '''\n",
    "    passed=True\n",
    "    G_size = random.randint(min_size,max_size)\n",
    "    p=random.uniform(min_sparsity, max_sparsity)\n",
    "    nxG = nx.fast_gnp_random_graph(G_size, p, seed=None, directed=True)\n",
    "    for e in nxG.edges():\n",
    "         nxG[e[0]][e[1]]['weight']=sp.rand()\n",
    "\n",
    "    A=nx.to_scipy_sparse_matrix(nxG)\n",
    "\n",
    "    iG=igraph.Graph(list(nxG.edges()), directed=True)\n",
    "    iG.es['weight'] = A.data\n",
    "    \n",
    "    customization_vector = np.random.random(G_size)\n",
    "    customization_dict = dict(enumerate(customization_vector.reshape(-1)))\n",
    "    return nxG, A, iG, customization_vector, customization_dict\n",
    "\n",
    "import unittest\n",
    "\n",
    "class TestMolerPageRank(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.number_of_tests = 10\n",
    "    def test_exact_pagerank(self):\n",
    "        damping_factor = 0.85\n",
    "        for i in range(self.number_of_tests):\n",
    "            nxG, A, iG, customization_vector, customization_dict = get_random_graph()\n",
    "\n",
    "            Xnx  = nx.pagerank_numpy(nxG, alpha=damping_factor, personalization = customization_dict) \n",
    "            Xnx =  np.array([v for k,v in Xnx.items() ])\n",
    "\n",
    "            Xml =  moler_pagerank(A, p=damping_factor, personalize=customization_vector)\n",
    "\n",
    "            assert_array_almost_equal(Xnx,  Xml, decimal = 5)\n",
    "        \n",
    "    def test_power_pagerank(self):\n",
    "        damping_factor = 0.85\n",
    "        tol = 1e-06\n",
    "        for i in range(self.number_of_tests):\n",
    "            nxG, A, iG, customization_vector, customization_dict = get_random_graph()\n",
    "\n",
    "            Ynx =  nx.pagerank_scipy(nxG, alpha=damping_factor, tol=tol, personalization=customization_dict)\n",
    "            Ynx =  np.array([v for k,v in Ynx.items() ])\n",
    "\n",
    "            Yml =  moler_pagerank_power(A, p=damping_factor, tol=tol, personalize=customization_vector)\n",
    "\n",
    "\n",
    "            assert_array_almost_equal(Ynx,  Yml, decimal = 5)\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python  ../test/pagerank_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "To avoid the clutter, we only visualize the fastest method from each implementation, that is: \n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile benchmarking.py\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import sys\n",
    "import networkx as nx\n",
    "from src.pagerank import moler_pagerank\n",
    "from src.pagerank import moler_pagerank_power\n",
    "from test.pagerank_test import get_random_graph\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "n = 5\n",
    "number_of_graphs = 20\n",
    "\n",
    "size_vector = sp.zeros(number_of_graphs)\n",
    "netx_pagerank_times = sp.zeros(number_of_graphs)\n",
    "netx_pagerank_times_numpy = sp.zeros(number_of_graphs)\n",
    "netx_pagerank_times_scipy = sp.zeros(number_of_graphs)\n",
    "moler_pagerank_times = sp.zeros(number_of_graphs)\n",
    "moler_pagerank_times_power = sp.zeros(number_of_graphs)\n",
    "ig_pagerank_times = sp.zeros(number_of_graphs)\n",
    "\n",
    "damping_factor = 0.85\n",
    "tol = 1e-3\n",
    "\n",
    "\n",
    "for i in range(number_of_graphs):\n",
    "    nxG, A, iG, customization_vector, customization_dict = get_random_graph(\n",
    "        min_size=100, max_size=1000)\n",
    "    size_vector[i] = nxG.number_of_edges()\n",
    "\n",
    "    netx_pagerank_times[i] = timeit.timeit(\n",
    "        lambda: nx.pagerank(\n",
    "            nxG,\n",
    "            alpha=damping_factor,\n",
    "            tol=tol),\n",
    "        number=n) / n\n",
    "    netx_pagerank_times_numpy[i] = timeit.timeit(\n",
    "        lambda: nx.pagerank_numpy(\n",
    "            nxG, alpha=damping_factor), number=n) / n\n",
    "    netx_pagerank_times_scipy[i] = timeit.timeit(\n",
    "        lambda: nx.pagerank_scipy(\n",
    "            nxG, alpha=damping_factor, tol=tol), number=n) / n\n",
    "\n",
    "    ig_pagerank_times[i] = timeit.timeit(\n",
    "        lambda: iG.personalized_pagerank(\n",
    "            directed=True,\n",
    "            damping=damping_factor,\n",
    "            weights=iG.es['weight'],\n",
    "            implementation=\"prpack\"),\n",
    "        number=n) / n\n",
    "\n",
    "    moler_pagerank_times[i] = timeit.timeit(\n",
    "        lambda: moler_pagerank(\n",
    "            A, p=damping_factor), number=n) / n\n",
    "    moler_pagerank_times_power[i] = timeit.timeit(\n",
    "        lambda: moler_pagerank_power(\n",
    "            A, p=damping_factor, tol=tol), number=n) / n\n",
    "\n",
    "\n",
    "argsort = size_vector.argsort()\n",
    "\n",
    "size_vector_sorted = size_vector[argsort]\n",
    "\n",
    "netx_pagerank_times_sorted = netx_pagerank_times[argsort]\n",
    "netx_pagerank_times_numpy_sorted = netx_pagerank_times_numpy[argsort]\n",
    "netx_pagerank_times_scipy_sorted = netx_pagerank_times_scipy[argsort]\n",
    "\n",
    "moler_pagerank_times_sorted = moler_pagerank_times[argsort]\n",
    "moler_pagerank_times_power_sorted = moler_pagerank_times_power[argsort]\n",
    "\n",
    "ig_pagerank_times_sorted = ig_pagerank_times[argsort]\n",
    "\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile plotting.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(num=None, figsize=(7, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.plot(size_vector_sorted, netx_pagerank_times_sorted, 'o-',  ms=8, lw=2,alpha=0.7, color='cyan', label='networkx.PageRank')\n",
    "#plt.plot(size_vector_sorted, netx_pagerank_times_numpy_sorted, 'v-', ms=8, lw=2,alpha=0.7, color='magenta', label='networkx.PageRank_numpy')\n",
    "plt.plot(size_vector_sorted, netx_pagerank_times_scipy_sorted, 'P-', ms=8, lw=2,alpha=0.7, color='blue', label='networkx.PageRank_scipy')\n",
    "\n",
    "plt.plot(size_vector_sorted, ig_pagerank_sorted, 'x-', ms=8, lw=2,alpha=0.7, color='black', label='iGraph_PageRank_ARPACK')\n",
    "\n",
    "plt.plot(size_vector_sorted, moler_pagerank_times, '*-', ms=8, lw=2,alpha=0.7, color='red', label='moler_pagerank_times')\n",
    "plt.plot(size_vector_sorted, moler_pagerank_times_power, '^-', ms=8, lw=2,alpha=0.7, color='green', label='moler_pagerank_times_Power')\n",
    "\n",
    "\n",
    "plt.xlabel('Number of the edges')\n",
    "plt.ylabel('Time (Seconds)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=2)\n",
    "plt.savefig('pagerank_exact.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Approximation Methods (Power Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(num=None, figsize=(7, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "argsort = size_vector.argsort()\n",
    "\n",
    "size_vector_sorted = size_vector[argsort]\n",
    "netx_pagerank_times_scipy_sorted = netx_pagerank_times_scipy[argsort]\n",
    "moler_pagerank_times_power_sorted = moler_pagerank_times_power[argsort]\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(size_vector_sorted, netx_pagerank_times_scipy_sorted, 'P-', ms=8, lw=2,alpha=0.7, color='black', label='networkx.PageRank_scipy')\n",
    "plt.plot(size_vector_sorted, moler_pagerank_times_power, '^-', ms=8, lw=2,alpha=0.7, color='green', label='moler_pagerank_times_Power')\n",
    "#plt.plot(size_vector_sorted, ig_pagerank, '^-', ms=8, lw=2,alpha=0.7, color='red', label='moler_pagerank_times_Power')\n",
    "\n",
    "plt.xlabel('Number of the edges')\n",
    "plt.ylabel('Time (Seconds)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=2)\n",
    "plt.savefig('pagerank.eps')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
