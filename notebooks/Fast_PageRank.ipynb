{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Personalized PageRank Implementation\n",
    "\n",
    "I needed a fast PageRank for Wikisim project, it has to be fast enough that can run in real time on relatively large graphs. Networkx was the obvious\n",
    "I implemented two versions of the algorithm in Python, both inspired  by the sparse fast solutions given in [**Cleve Moler**](https://en.wikipedia.org/wiki/Cleve_Moler)'s book, [*Experiments with MATLAB*](https://www.mathworks.com/content/dam/mathworks/mathworks-dot-com/moler/exm/chapters/pagerank.pdf). The power method is much faster with enough precision for our task. \n",
    "\n",
    "## Personalized PageRank\n",
    "I modified the algorithm a little bit to be able to calculate **personalized PageRank** as well. \n",
    "\n",
    "\n",
    "## Comparison with Popular Python Implementations: Networkx and iGraph\n",
    "Both of the implementation (exact Solution and *power method*) are much faster than their correspondent method in NetworkX. The *power method* is also faster than the iGraph latest implementation, *PRPACK*, which is also and eigen-value based implementation. \n",
    "\n",
    "## What is Google PageRank Algorithm?\n",
    "\n",
    "PageRank** is another link analysis algorithm primarily used to rank search engine results. It is defined as a process in which starting  from a\n",
    "random node, a random walker moves to a\trandom neighbour with probability $\\alpha$  or jumps to a random vertex with the probability $1-\\alpha$ . The PageRank values are the limiting probabilities of finding a walker on each \n",
    "node.\n",
    "\n",
    "## How is Google PageRank Calculated?\n",
    "\n",
    "Let $\\mathbf{A}$ be the adjacency matrix ($\\mathbf{A}_ij$ is the weight of the edge from node $i$ to node $j$). Before we continue, we need to take care of a problem: nodes with no outlink, a.k.a, *dangling nodes*. What happens when you hit a page with no out_link? You only have one option and that is to jump to a random page. To simulate this behavior we augment $\\mathbf{A}$ by adding a link from every dangling node to every other node in the network, all with equal weights. In other words, we create a $\\mathbf{\\bar{A}}$ replace an all zero rows by all $1/n$ rows, or algebraically: we define $\\vec{r}$ to be the vector of row-wise sum of the elements of $\\mathbf{A}$, that is $\\vec{r}_i=\\sum_{j}A_{ij}$. If $\\mathbf{B}$ is defined to be a matrix that its $i$-th row is  all $1/n$ if  $\\vec{r}_i=0$, or all $0$ if $\\vec{r}_i\\neq 0$, then we can define $\\mathbf{\\bar{A}}$ as $\\mathbf{A}+\\mathbf{B}$\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{\\bar{A}}&=\\mathbf{A}+\\mathbf{B}\\\\\n",
    "\\mbox{where}\\\\\n",
    "\\mathbf{B}_{ij} &= \\begin{cases}\n",
    "                1/n & \\mbox{if } r_i=0 \\\\ \n",
    "                0   & \\mbox{else}\n",
    "                \\end{cases} \\\\  \n",
    "\\end{align}\n",
    "\n",
    "Probability of being at a node $a$ at time $t+1$  is the sum over the out-neighbors b of a of the probability that the walk was at b at time t, times the probability\n",
    "it moved from b to a in time $t+1$: \n",
    "\\begin{equation}\n",
    "    \\vec{p}=\\sum_{b:(a,b)\\in E}\\frac{A(b,a)}{d(b)}\\vec{p}_t(b)+(1-\\alpha)\\frac{1}{n}\\vec{1} .\n",
    "\\end{equation}\n",
    "\n",
    "To give a matrix form, we define $\\mathbf{\\bar{D}}$ be the diagonal matrix with the out-degree  of each node in $\\mathbf{\\bar{A}}$ on \n",
    "the diagonal. If we set $\\mathbf{\\bar{W}}=\\mathbf{\\bar{A}}^T \\mathbf{\\bar{D}}^{-1}$, then the Pagerank\n",
    "vector, initialized with $\\vec{1}/n$, can be obtained from the following\n",
    "recursion: \n",
    "\\begin{equation}\n",
    "    \\vec{pr}_{t+1}=(1-\\alpha)\\frac{1}{n}\\vec{1}+\\alpha \\matr{W}\\vec{pr}_{t}.\n",
    "\\end{equation}\n",
    "Let $\\vec{e}$ be ...\n",
    "So $p$, the stationary probabilities (where $\\vec{p}_{t+1}=\\vec{p}_t=\\vec{p}$ can be calculated by either\n",
    "\n",
    "1. Linear System Solving\n",
    "We can solve the equation and get \n",
    "\\begin{equation}\n",
    "    p=\\frac{1-\\alpha}{n}(I-\\alpha \\matr{W})^{-1}\\vec{1}.\n",
    "\\end{equation}\n",
    "And use a linear system solber to calculate $\\vec{p}$\n",
    "\n",
    "2. Power-Method\n",
    "Basically calculating the equation until it converges. \n",
    "\n",
    "\n",
    "\n",
    "## How Fast Google PageRank Is Calculated?\n",
    "To speed up the calculations we need to take advantage of the sparse matrix calculations. The first equation can be directly  solved using scipy sparse linear solver. However, the power method can be very faster if properly implemented. The only problem with the current formulation  that $\\mathbf{\\bar{A}}$ has lower sparsity than the original $\\mathbf{A}$. However, we can move around pieces of the equation a little bit. \n",
    "It's easy to see $\\mathbf{\\bar{W}}=\\mathbf{W}+\\mathbf{B}$, where similar to how we defined $\\mathbf{\\bar{W}}$, let $\\mathbf{\\bar{D}}$ be the diagonal matrix with the out-degree  of each node in $\\mathbf{A} and\n",
    "\\begin{equation}\n",
    "$\\mathbf{W}=\\mathbf{A}^T \\mathbf{D}^{-1}\n",
    "\\end{equation}\n",
    "and also, $\\vec{1}=\\vec{p}$\n",
    "We can rewriting the recursion:\n",
    "\\begin{align}\n",
    "    \\vec{pr}_{t+1} &= (1-\\alpha)\\frac{1}{n}\\vec{1}+\\alpha \\mathbf{\\bar{W}}\\vec{pr}_{t}\\\\\n",
    "                   &= (1-\\alpha)\\frac{1}{n}\\vec{1}+\\alpha (\\mathbf{W}+\\mathbf{B})\\vec{pr}_{t}\\\\\n",
    "                   &= (1-\\alpha)\\frac{1}{n}\\vec{1}+\\alpha \\mathbf{W}\\vec{pr}_{t}+\\mathbf{B})\\vec{pr}_{t}\n",
    "                   &= \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "# What is the major drawback of Networkx PageRank?\n",
    "I gave up using Networkx for one simple reason: I had to calculate PageRank many many times, and my internal representation of a graph was a simple sparse matrix. Every time I wanted to calculate PageRank I had to translate it to the graph representation of Networkx, which was slow. My benchmarking shows that Networkx has a pretty fast implementation of PageRank but it also has to translate from its own graph datastructure to a csr matrix, and that's exactly where the algorithm slows down! I still don't understand why on earth they don't simply use a csr matrix. \n",
    "\n",
    "#References\n",
    "\n",
    "http://www.cs.yale.edu/homes/spielman/561/lect10-18.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "i\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pagerank_old.py\n",
    "\"\"\"Two fast implementations of PageRank: \n",
    "    An exact solution using a sparse linear system solver, and an a power method approximation. \n",
    "    Both solutions are taking full advantage of sparse matrix calculations.\n",
    "    \n",
    "    [Reference]:\n",
    "    Cleve Moler. 2011. Experiments with MATLAB (Electronic ed.). MathWorks, Inc.\n",
    "\"\"\"\n",
    "# uncomment\n",
    "from __future__ import division\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.sparse as sprs\n",
    "import scipy.spatial\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "__author__ = \"Armin Sajadi\"\n",
    "__copyright__ = \"Copyright 2015, The Wikisim Project\"\n",
    "__email__ = \"asajadi@gmail.com\"\n",
    "\n",
    "\n",
    "def pagerank_old(G, p=0.85,\n",
    "             personalize=None, reverse=False):\n",
    "    \"\"\" Calculates PageRank given a csr graph\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "\n",
    "    G: a csr graph.\n",
    "    p: damping factor\n",
    "    personlize: if not None, should be an array with the size of the nodes\n",
    "                containing probability distributions.\n",
    "                It will be normalized automatically\n",
    "    reverse: If true, returns the reversed-PageRank\n",
    "\n",
    "    outputs\n",
    "    -------\n",
    "\n",
    "    PageRank Scores for the nodes\n",
    "\n",
    "    \"\"\"\n",
    "    # In Moler's algorithm, $G_{ij}$ represents the existences of an edge\n",
    "    # from node $j$ to $i$, while we have assumed the opposite!\n",
    "    if not reverse:\n",
    "        G = G.T\n",
    "\n",
    "    n, _ = G.shape\n",
    "    c = sp.asarray(G.sum(axis=0)).reshape(-1)\n",
    "\n",
    "    k = c.nonzero()[0]\n",
    "\n",
    "    D = sprs.csr_matrix((1 / c[k], (k, k)), shape=(n, n))\n",
    "\n",
    "    if personalize is None:\n",
    "        personalize = sp.ones(n)\n",
    "    personalize = personalize.reshape(n, 1)\n",
    "    e = (personalize / personalize.sum()) * n\n",
    "\n",
    "    I = sprs.eye(n)\n",
    "    x = sprs.linalg.spsolve((I - p * G.dot(D)), e)\n",
    "\n",
    "    x = x / x.sum()\n",
    "    return x\n",
    "\n",
    "\n",
    "def pagerank_power_old(G, p=0.85, max_iter=100,\n",
    "                   tol=1e-06, personalize=None, reverse=False):\n",
    "    \"\"\" Calculates PageRank given a csr graph\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    G: a csr graph.\n",
    "    p: damping factor\n",
    "    max_iter: maximum number of iterations\n",
    "    personlize: if not None, should be an array with the size of the nodes\n",
    "                containing probability distributions.\n",
    "                It will be normalized automatically.\n",
    "    reverse: If true, returns the reversed-PageRank\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    PageRank Scores for the nodes\n",
    "\n",
    "    \"\"\"\n",
    "    # In Moler's algorithm, $G_{ij}$ represents the existences of an edge\n",
    "    # from node $j$ to $i$, while we have assumed the opposite!\n",
    "    if not reverse:\n",
    "        G = G.T\n",
    "\n",
    "    n, _ = G.shape\n",
    "    c = sp.asarray(G.sum(axis=0)).reshape(-1)\n",
    "\n",
    "    k = c.nonzero()[0]\n",
    "\n",
    "    D = sprs.csr_matrix((1 / c[k], (k, k)), shape=(n, n))\n",
    "\n",
    "    if personalize is None:\n",
    "        personalize = sp.ones(n)\n",
    "    personalize = personalize.reshape(n, 1)\n",
    "    e = (personalize / personalize.sum()) * n\n",
    "\n",
    "    z = (((1 - p) * (c != 0) + (c == 0)) / n)[sp.newaxis, :]\n",
    "    G = p * G.dot(D)\n",
    "\n",
    "    x = e / n\n",
    "    oldx = sp.zeros((n, 1))\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    while sp.linalg.norm(x - oldx) > tol:\n",
    "        oldx = x\n",
    "        x = G.dot(x) + e.dot(z.dot(x))\n",
    "        iteration += 1\n",
    "        if iteration >= max_iter:\n",
    "            break\n",
    "    x = x / sum(x)\n",
    "\n",
    "    return x.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile ../src/pagerank.py\n",
    "\"\"\"Two fast implementations of PageRank: \n",
    "    An exact solution using a sparse linear system solver, and an a power method approximation. \n",
    "    Both solutions are taking full advantage of sparse matrix calculations.\n",
    "    \n",
    "    [Reference]:\n",
    "    Cleve Moler. 2011. Experiments with MATLAB (Electronic ed.). MathWorks, Inc.\n",
    "\"\"\"\n",
    "# uncomment\n",
    "from __future__ import division\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.sparse as sprs\n",
    "import scipy.spatial\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "__author__ = \"Armin Sajadi\"\n",
    "__copyright__ = \"Copyright 2015, The Wikisim Project\"\n",
    "__email__ = \"asajadi@gmail.com\"\n",
    "\n",
    "\n",
    "def pagerank(A, p=0.85,\n",
    "             personalize=None, reverse=False):\n",
    "    \"\"\" Calculates PageRank given a csr graph\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "\n",
    "    G: a csr graph.\n",
    "    p: damping factor\n",
    "    personlize: if not None, should be an array with the size of the nodes\n",
    "                containing probability distributions.\n",
    "                It will be normalized automatically\n",
    "    reverse: If true, returns the reversed-PageRank\n",
    "\n",
    "    outputs\n",
    "    -------\n",
    "\n",
    "    PageRank Scores for the nodes\n",
    "\n",
    "    \"\"\"\n",
    "    # In Moler's algorithm, $A_{ij}$ represents the existences of an edge\n",
    "    # from node $j$ to $i$, while we have assumed the opposite!\n",
    "    if reverse:\n",
    "        A = A.T\n",
    "\n",
    "    n, _ = A.shape\n",
    "    r = sp.asarray(A.sum(axis=1)).reshape(-1)\n",
    "\n",
    "    k = r.nonzero()[0]\n",
    "\n",
    "    D_1 = sprs.csr_matrix((1 / r[k], (k, k)), shape=(n, n))\n",
    "\n",
    "    if personalize is None:\n",
    "        personalize = sp.ones(n)\n",
    "    personalize = personalize.reshape(n, 1)\n",
    "    e = (personalize / personalize.sum()) * n\n",
    "\n",
    "    I = sprs.eye(n)\n",
    "    x = sprs.linalg.spsolve((I - p * A.T @ D_1), e)\n",
    "\n",
    "    x = x / x.sum()\n",
    "    return x\n",
    "\n",
    "\n",
    "def pagerank_power(A, p=0.85, max_iter=100,\n",
    "                   tol=1e-06, personalize=None, reverse=False):\n",
    "    \"\"\" Calculates PageRank given a csr graph\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    A: a csr graph.\n",
    "    p: damping factor\n",
    "    max_iter: maximum number of iterations\n",
    "    personlize: if not None, should be an array with the size of the nodes\n",
    "                containing probability distributions.\n",
    "                It will be normalized automatically.\n",
    "    reverse: If true, returns the reversed-PageRank\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    PageRank Scores for the nodes\n",
    "\n",
    "    \"\"\"\n",
    "    # In Moler's algorithm, $G_{ij}$ represents the existences of an edge\n",
    "    # from node $j$ to $i$, while we have assumed the opposite!\n",
    "    if reverse:\n",
    "        A = A.T\n",
    "\n",
    "    n, _ = A.shape\n",
    "    r = sp.asarray(A.sum(axis=1)).reshape(-1)\n",
    "\n",
    "    k = r.nonzero()[0]\n",
    "\n",
    "    D_1 = sprs.csr_matrix((1 / r[k], (k, k)), shape=(n, n))\n",
    "\n",
    "    if personalize is None:\n",
    "        personalize = sp.ones(n)\n",
    "    personalize = personalize.reshape(n, 1)\n",
    "    e = (personalize / personalize.sum()) * n\n",
    "\n",
    "    z = (((1 - p) * (r != 0) + (r == 0)) / n)[sp.newaxis, :]\n",
    "    G = p * A.T @ D_1\n",
    "\n",
    "    x = e / n\n",
    "    oldx = sp.zeros((n, 1))\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    while sp.linalg.norm(x - oldx) > tol:\n",
    "        oldx = x\n",
    "        x = G @ x + e @ (z @ x)\n",
    "        iteration += 1\n",
    "        if iteration >= max_iter:\n",
    "            break\n",
    "    x = x / sum(x)\n",
    "\n",
    "    return x.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import timeit\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import networkx as nx\n",
    "sys.path.insert(0, '..')\n",
    "from src.pagerank_old import pagerank_old\n",
    "from src.pagerank_old import pagerank_power_old\n",
    "import scipy.sparse as sprs\n",
    "\n",
    "tol=1e-10\n",
    "max_iter=1000\n",
    "for i in range(5):\n",
    "    n = random.randint(5, 10)\n",
    "    p = random.uniform(0.1, 0.8)\n",
    "    damping_factor = random.uniform(0.1, 1)\n",
    "\n",
    "    A = sprs.random(n, n, density=p)\n",
    "        \n",
    "    personalize_vector = sp.random.random(n)        \n",
    "    x_old = pagerank_old(A, p=damping_factor, personalize=personalize_vector)\n",
    "    x = pagerank(A, p=damping_factor, personalize=personalize_vector)\n",
    "    print(sp.allclose(x_old, x, rtol=0, atol=1e-10))\n",
    "    \n",
    "    y_old = pagerank_power_old(A, p=damping_factor, personalize=personalize_vector, tol=tol, max_iter=max_iter)\n",
    "    y = pagerank_power(A, p=damping_factor, personalize=personalize_vector, tol=tol, max_iter=max_iter)\n",
    "    #print(sp.linalg.norm(y_old- y))\n",
    "    print(sp.allclose(y_old, y, rtol=0, atol=1e-10))\n",
    "    \n",
    "    #print(y_old)\n",
    "    #print(y)\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../test/pagerank_test.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import scipy as sp\n",
    "import scipy.sparse as sparse\n",
    "from numpy.testing import assert_allclose\n",
    "import unittest\n",
    "\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    os.path.abspath(\n",
    "        os.path.join(\n",
    "            os.path.dirname(__file__),\n",
    "            '..')))\n",
    "\n",
    "from src.pagerank import pagerank_power\n",
    "from src.pagerank import pagerank\n",
    "\n",
    "class TestMolerPageRank(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # ---G1---\n",
    "        n1 = 5\n",
    "        rows1 = [0, 1, 2, 2, 2, 3, 3, 4, 4, 4]\n",
    "        cols1 = [1, 2, 1, 3, 4, 0, 2, 0, 2, 3]\n",
    "        data1 = [\n",
    "            0.4923, 0.0999, 0.2132, 0.0178, 0.5694,\n",
    "            0.0406, 0.2047, 0.861, 0.3849, 0.4829]\n",
    "\n",
    "        self.p1 = 0.83\n",
    "        self.personalize1 = sp.array([0.6005, 0.1221, 0.2542, 0.4778, 0.4275])\n",
    "        self.G1 = sparse.csr_matrix((data1, (rows1, cols1)), shape=(n1, n1))\n",
    "        self.pr1 = sp.array([0.1592, 0.2114, 0.3085, 0.1, 0.2208])\n",
    "\n",
    "        # ---G2---\n",
    "        n2 = 10\n",
    "        rows2 = [2, 2, 4, 5, 5, 5, 6, 6, 9, 9]\n",
    "        cols2 = [4, 5, 5, 3, 4, 9, 1, 2, 2, 4]\n",
    "        data2 = [\n",
    "            0.4565, 0.2861, 0.573, 0.0025, 0.4829,\n",
    "            0.3866, 0.3041, 0.3407, 0.2653, 0.8079]\n",
    "        self.G2 = sparse.csr_matrix((data2, (rows2, cols2)), shape=(n2, n2))\n",
    "        self.personalize2 = sp.array([0.8887, 0.6491, 0.7843, 0.7103, 0.7428,\n",
    "                                      0.6632, 0.7351, 0.3006, 0.8722, 0.1652])\n",
    "        self.p2 = 0.92\n",
    "        self.pr2 = sp.array([0.0234, 0.0255, 0.0629, 0.0196, 0.3303,\n",
    "                             0.3436, 0.0194, 0.0079, 0.023, 0.1445])\n",
    "\n",
    "        # ---G3---\n",
    "        n3 = 5\n",
    "        rows3 = [2]\n",
    "        cols3 = [4]\n",
    "        data3 = [0.5441]\n",
    "        self.G3 = sparse.csr_matrix((data3, (rows3, cols3)), shape=(n3, n3))\n",
    "\n",
    "        self.personalize3 = sp.array([0.0884, 0.2797, 0.3093, 0.5533, 0.985])\n",
    "        self.p3 = 0.81\n",
    "        self.pr3 = sp.array([0.0358, 0.1134, 0.1254, 0.2244, 0.501])\n",
    "\n",
    "        # ---G4---\n",
    "        n4 = 5\n",
    "        rows4 = []\n",
    "        cols4 = []\n",
    "        data4 = []\n",
    "        self.G4 = sparse.csr_matrix((data4, (rows4, cols4)), shape=(n4, n4))\n",
    "\n",
    "        self.personalize4 = sp.array([0.2534, 0.8945, 0.9562, 0.056, 0.9439])\n",
    "        self.p4 = 0.70\n",
    "        self.pr4 = sp.array([0.0816, 0.2882, 0.3081, 0.018, 0.3041])\n",
    "\n",
    "        # ---G5---\n",
    "        n5 = 0\n",
    "        rows5 = []\n",
    "        cols5 = []\n",
    "        data5 = []\n",
    "        self.G5 = sparse.csr_matrix((data5, (rows5, cols5)), shape=(n5, n5))\n",
    "\n",
    "        self.personalize5 = sp.array([])\n",
    "        self.p5 = 0.70\n",
    "        self.pr5 = sp.array([])\n",
    "\n",
    "    def test_pagerank_1(self):\n",
    "        calculated_pagerank = pagerank(self.G1, p=self.p1,\n",
    "                                       personalize=self.personalize1)\n",
    "        assert_allclose(calculated_pagerank, self.pr1, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_pagerank_2(self):\n",
    "\n",
    "        calculated_pagerank = pagerank(self.G2, p=self.p2,\n",
    "                                       personalize=self.personalize2)\n",
    "        assert_allclose(calculated_pagerank, self.pr2, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_single_edge(self):\n",
    "        calculated_pagerank = pagerank(self.G3, p=self.p3,\n",
    "                                       personalize=self.personalize3)\n",
    "        assert_allclose(calculated_pagerank, self.pr3, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_zero_edge(self):\n",
    "        calculated_pagerank = pagerank(self.G4, p=self.p4,\n",
    "                                       personalize=self.personalize4)\n",
    "        assert_allclose(calculated_pagerank, self.pr4, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_empty_graph(self):\n",
    "        calculated_pagerank = pagerank(self.G5, p=self.p5,\n",
    "                                       personalize=self.personalize5)\n",
    "        self.assertEqual(calculated_pagerank.size, 0)\n",
    "\n",
    "    def test_power_pagerank_1(self):\n",
    "        calculated_pagerank = pagerank_power(self.G1, p=self.p1,\n",
    "                                             personalize=self.personalize1)\n",
    "        assert_allclose(calculated_pagerank, self.pr1, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_power_pagerank_2(self):\n",
    "\n",
    "        calculated_pagerank = pagerank_power(self.G2, p=self.p2,\n",
    "                                             personalize=self.personalize2)\n",
    "        assert_allclose(calculated_pagerank, self.pr2, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_power_single_edge(self):\n",
    "        calculated_pagerank = pagerank_power(self.G3, p=self.p3,\n",
    "                                             personalize=self.personalize3)\n",
    "        assert_allclose(calculated_pagerank, self.pr3, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_power_zero_edge(self):\n",
    "        calculated_pagerank = pagerank_power(self.G4, p=self.p4,\n",
    "                                             personalize=self.personalize4)\n",
    "        assert_allclose(calculated_pagerank, self.pr4, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_power_empty_graph(self):\n",
    "        calculated_pagerank = pagerank_power(self.G5, p=self.p5,\n",
    "                                             personalize=self.personalize5)\n",
    "        self.assertEqual(calculated_pagerank.size, 0)\n",
    "\n",
    "\n",
    "#             assert_array_almost_equal(Ynx,  Yml, decimal = 5)\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python  ../test/pagerank_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "To avoid the clutter, we only visualize the fastest method from each implementation, that is: \n",
    "\n",
    "- `networkx.pagerank_scipy`\n",
    "- Latest implementation of  `iGraph.personalized_pagerank` (PRPACK)\n",
    "- Our `pagerank_power` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import timeit\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import igraph\n",
    "import networkx as nx\n",
    "sys.path.insert(0, '..')\n",
    "from src.pagerank import pagerank\n",
    "from src.pagerank import pagerank_power\n",
    "\n",
    "\n",
    "def get_random_graph(\n",
    "        min_size=100,\n",
    "        max_size=300,\n",
    "        min_sparsity=0.1,\n",
    "        max_sparsity=0.5):\n",
    "    ''' Creates a random graph and a teleport vector and output them\n",
    "        in different formats for different algorithms\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "\n",
    "    min_size and max_size: The size of the graph will be a random number\n",
    "        in the range of (min_size, max_size)\n",
    "    min_sparsity and max_sparsity: The sparcity of the graph\n",
    "        will be a random number in the range of (min_sparsity, max_sparsity)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    nxG: A random Graph for NetworkX\n",
    "    A: The equivallent csr Adjacency matrix, for our PageRank\n",
    "    iG: The equivallent iGraph\n",
    "    personalize_vector: Personalization probabily vector\n",
    "    personalize_dict: Personalization probabily vector,\n",
    "                    in the form of a dictionary for NetworkX\n",
    "\n",
    "    '''\n",
    "    G_size = random.randint(min_size, max_size)\n",
    "    p = random.uniform(min_sparsity, max_sparsity)\n",
    "    nxG = nx.fast_gnp_random_graph(G_size, p, seed=None, directed=True)\n",
    "    for e in nxG.edges():\n",
    "        nxG[e[0]][e[1]]['weight'] = sp.rand()\n",
    "\n",
    "    A = nx.to_scipy_sparse_matrix(nxG)\n",
    "\n",
    "    iG = igraph.Graph(list(nxG.edges()), directed=True)\n",
    "    iG.es['weight'] = A.data\n",
    "\n",
    "    personalize_vector = sp.random.random(G_size)\n",
    "    personalize_dict = dict(enumerate(personalize_vector.reshape(-1)))\n",
    "    return nxG, A, iG, personalize_vector, personalize_dict\n",
    "\n",
    "\n",
    "n = 5\n",
    "number_of_graphs = 20\n",
    "\n",
    "size_vector = sp.zeros(number_of_graphs)\n",
    "netx_pagerank_times = sp.zeros(number_of_graphs)\n",
    "netx_pagerank_times_numpy = sp.zeros(number_of_graphs)\n",
    "netx_pagerank_times_scipy = sp.zeros(number_of_graphs)\n",
    "pagerank_times = sp.zeros(number_of_graphs)\n",
    "pagerank_times_power = sp.zeros(number_of_graphs)\n",
    "ig_pagerank_times = sp.zeros(number_of_graphs)\n",
    "\n",
    "damping_factor = 0.85\n",
    "tol = 1e-3\n",
    "\n",
    "\n",
    "for i in range(number_of_graphs):\n",
    "    nxG, A, iG, personalize_vector, personalize_dict = get_random_graph(\n",
    "        min_size=100, max_size=1000)\n",
    "    size_vector[i] = nxG.number_of_edges()\n",
    "\n",
    "    netx_pagerank_times[i] = timeit.timeit(\n",
    "        lambda: nx.pagerank(nxG, alpha=damping_factor, tol=tol),\n",
    "        number=n) / n\n",
    "    netx_pagerank_times_numpy[i] = timeit.timeit(\n",
    "        lambda: nx.pagerank_numpy(nxG, alpha=damping_factor),\n",
    "        number=n) / n\n",
    "    netx_pagerank_times_scipy[i] = timeit.timeit(\n",
    "        lambda: nx.pagerank_scipy(nxG, alpha=damping_factor, tol=tol),\n",
    "        number=n) / n\n",
    "    ig_pagerank_times[i] = timeit.timeit(\n",
    "        lambda: iG.personalized_pagerank(directed=True,\n",
    "                                         damping=damping_factor,\n",
    "                                         weights=iG.es['weight'],\n",
    "                                         implementation=\"prpack\"),\n",
    "        number=n) / n\n",
    "    pagerank_times[i] = timeit.timeit(\n",
    "        lambda: pagerank(A, p=damping_factor),\n",
    "        number=n) / n\n",
    "    pagerank_times_power[i] = timeit.timeit(\n",
    "        lambda: pagerank_power(A, p=damping_factor, tol=tol),\n",
    "        number=n) / n\n",
    "\n",
    "\n",
    "argsort = size_vector.argsort()\n",
    "\n",
    "size_vector_sorted = size_vector[argsort]\n",
    "\n",
    "netx_pagerank_times_sorted = netx_pagerank_times[argsort]\n",
    "netx_pagerank_times_numpy_sorted = netx_pagerank_times_numpy[argsort]\n",
    "netx_pagerank_times_scipy_sorted = netx_pagerank_times_scipy[argsort]\n",
    "\n",
    "pagerank_times_sorted = pagerank_times[argsort]\n",
    "pagerank_times_power_sorted = pagerank_times_power[argsort]\n",
    "\n",
    "ig_pagerank_times_sorted = ig_pagerank_times[argsort]\n",
    "\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(num=None, figsize=(7, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "\n",
    "# plt.plot(size_vector_sorted, netx_pagerank_times_sorted,\n",
    "#          'o-', ms=8, lw=2, alpha=0.7, color='cyan',\n",
    "#          label='networkx.PageRank')\n",
    "# plt.plot(size_vector_sorted, netx_pagerank_times_numpy_sorted,\n",
    "#          'v-', ms=8, lw=2, alpha=0.7, color='magenta',\n",
    "#          label='networkx.PageRank_numpy')\n",
    "\n",
    "plt.plot(size_vector_sorted, netx_pagerank_times_scipy_sorted,\n",
    "         'P-', ms=8, lw=2, alpha=0.7, color='blue',\n",
    "         label='networkx.PageRank_scipy')\n",
    "\n",
    "plt.plot(size_vector_sorted, ig_pagerank_times_sorted,\n",
    "         'x-', ms=8, lw=2, alpha=0.7, color='black',\n",
    "         label='iGraph_PageRank_ARPACK')\n",
    "\n",
    "# plt.plot(size_vector_sorted, pagerank_times,\n",
    "#          '*-', ms=8, lw=2, alpha=0.7, color='red',\n",
    "#          label='pagerank_times')\n",
    "plt.plot(size_vector_sorted, pagerank_times_power,\n",
    "         '^-', ms=8, lw=2, alpha=0.7, color='green',\n",
    "         label='pagerank_times_Power')\n",
    "\n",
    "\n",
    "plt.xlabel('Number of the edges')\n",
    "plt.ylabel('Time (Seconds)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=2)\n",
    "plt.savefig('pagerank.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import random\n",
    "A = random(5, 6, density=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
