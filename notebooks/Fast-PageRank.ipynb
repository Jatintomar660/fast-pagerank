{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Personalized PageRank Implementation\n",
    "\n",
    "I needed a fast PageRank for Wikisim project, it has to be fast enough to run real time on relatively large graphs. Networkx was the obvious tool to use, however, it needed back and forth translation from my graph representation (which was the pretty standard csr matrix), to its internal graph data structure. These translations were slowing down the process. \n",
    "\n",
    "I implemented two versions of the algorithm in Python, both inspired by the sparse fast solutions given in [**Cleve Moler**](https://en.wikipedia.org/wiki/Cleve_Moler)'s book, [*Experiments with MATLAB*](https://www.mathworks.com/content/dam/mathworks/mathworks-dot-com/moler/exm/chapters/pagerank.pdf). The power method is much faster with enough precision for our task. \n",
    "\n",
    "### Personalized PageRank\n",
    "I modified the algorithm a little bit to be able to calculate **personalized PageRank** as well. \n",
    "\n",
    "\n",
    "### Comparison with Popular Python Implementations: Networkx and iGraph\n",
    "Both implementations (exact solution and *power method*) are much faster than their correspondent methods in NetworkX. The *power method* is also faster than the iGraph latest implementation, *PRPACK*, which is also an eigen-vector based implementation. \n",
    "\n",
    "### What is the major drawback of Networkx PageRank?\n",
    "I gave up using Networkx for one simple reason: I had to calculate PageRank several times, and my internal representation of a graph was a simple sparse matrix. Every time I wanted to calculate PageRank I had to translate it to the graph representation of Networkx, which was slow. My benchmarking shows that Networkx  has a pretty fast implementation of PageRank (I mean `networkx.pagerank_scipy`, the other two, `networkx.pagerank` and `networkx.pagerank_numpy` are terrible, don't even try them!) but it also has to translate from its own graph data structure to a csr matrix before doing the actual calculations, and that's exactly where the algorithm slows down! I still don't understand why on earth they don't simply use a csr matrix. \n",
    "\n",
    "**Note**: To be fair, I could've even counted the `nx.from_scipy_sparse_matrix`, because that was another bottleneck for me, and for many other cases that you have a `csr` adjacency matrix.\n",
    "\n",
    "### Python Implementation\n",
    "The python package is hosted at https://github.com/asajadi/fast-pagerank and you can find the installation guide in the [README.md](https://github.com/asajadi/fast-pagerank/blob/master/README.md) file.  You also can find this jupyter notebook in [the notebook directory](https://github.com/asajadi/fast-pagerank/blob/master/notebooks/Fast-PageRank.ipynb). \n",
    "\n",
    "## Appendix\n",
    "\n",
    "### What is Google PageRank Algorithm?\n",
    "PageRank is another link analysis algorithm primarily used to rank search engine results. It is defined as a process in which starting  from a\n",
    "random node, a random walker moves to a\trandom neighbour with probability $\\alpha$  or jumps to a random vertex with the probability $1-\\alpha$ . The PageRank values are the limiting probabilities of finding a walker on each \n",
    "node. In the original PageRank, the jump can be to any node with a uniform probability, however later in **Personalized PageRank**, this can be any custom probability distribution over the nodes. \n",
    "\n",
    "### How is Google PageRank Calculated? [1, 2]\n",
    "\n",
    "Let $\\mathbf{A}$ be the adjacency matrix ($\\mathbf{A}_{ij}$ is the weight of the edge from node $i$ to node $j$) and $\\vec{s}$ be the *teleprorting probability*, that is $\\vec{s}_i$ is the probability of jumping to node $i$. Probability of being at node $j$ at time $t+1$  can be determined by two factors: \n",
    "1. Sum over the out-neighbors $i$ of $j$ of the probability that the walk was at $i$ at time t, times the probability it moved from $i$ to $j$ in time $t+1$.\n",
    "2. Probability of teleporting from somewhere else in the graph to $j$.\n",
    " \n",
    "\\begin{equation}\n",
    "    \\vec{p}_{t+1}(j)=\\alpha\\sum_{i:(i,j)\\in E}\\frac{A(i,j)}{d(i)}\\vec{p}_t(i)+(1-\\alpha)\\vec{s}_j,\n",
    "\\end{equation}\n",
    "\n",
    "where $d(i)$ is the out-degree of node $i$.\n",
    "To give a matrix form, we define $\\mathbf{D}$ be the diagonal matrix with the out-degree  of each node in $\\mathbf{A}$ on \n",
    "the diagonal. Then the PageRank\n",
    "vector, initialized with $\\vec{s}$, can be obtained from the following recursion: \n",
    "\n",
    "\\begin{equation}\n",
    "    \\vec{pr}_{t+1}=\\alpha \\mathbf{A}^T \\mathbf{D}^{-1}\\vec{pr}_{t}+(1-\\alpha)\\vec{s}.\n",
    "\\end{equation}\n",
    "\n",
    "There is a serious problem that we need to take care: $\\mathbf{D}^{-1}$ is the inverse of $\\mathbf{D}$, which for a diagonal matrix it will be simply inverting the elements on the diagonal. This will break if there are nodes with no out neighbors, a.k.a, *dangling nodes*.\n",
    "What happens when you hit a page with no out link? You only have one option and that is to jump to a random page.\n",
    "\n",
    "To simulate this behavior we alter $\\mathbf{A}$ by adding an edge from every dangling node to every other node $j$ with a weight of $\\vec{s}_j$. In other words, we create $\\mathbf{\\bar{A}}$ by replacing each all zero row by $\\vec{s}^T$. Formally, if we define $\\vec{r}$ to be the vector of row-wise sum of the elements of $\\mathbf{A}$, that is $\\vec{r}_i=\\sum_{j}A_{ij}$, then:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{\\bar{A}}&=\\mathbf{A}+\\mathbf{B}\\\\\n",
    "\\mbox{where}\\\\\n",
    "\\mathbf{B}_{ij} &= \\begin{cases}\n",
    "                        \\vec{s}_j & \\mbox{if } r_i=0 \\\\ \n",
    "                        0   & \\mbox{else}\n",
    "                    \\end{cases} \\\\  \n",
    "\\end{align}\n",
    "\n",
    "We need to re-define $\\mathbf{D}$. In our new definition of $\\mathbf{D}$, we ignore nodes with no out-neighbors (or in other words, replace $\\frac{1}{0}$ by $0$). Similar to $\\mathbf{D}$, we define $\\mathbf{\\bar{D}}$ to be the diagonal matrix of the out-degrees of $\\mathbf{\\bar{A}}$. So we can re-write the recursion as:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\vec{pr}_{t+1}=\\alpha \\mathbf{\\bar{A}}^T \\mathbf{\\bar{D}}^{-1}\\vec{pr}_{t}+(1-\\alpha)\\vec{s}.\\qquad\\mbox{(I)}\n",
    "\\end{equation}\n",
    "\n",
    "Now $\\vec{pr}$, the stationary probabilities (i.e, when $\\vec{pr}_{t+1}=\\vec{pr}_t=\\vec{pr}$) can be calculated by either of the following approaches:\n",
    "\n",
    "**1. Linear System Solving**\n",
    "\n",
    "We can solve Eq. $\\mbox{(I)}$ and get:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\vec{pr}=(I-\\alpha\\mathbf{\\bar{A}}^T \\mathbf{\\bar{D}}^{-1})(1-\\alpha)\\vec{s}.\n",
    "\\end{equation}\n",
    "\n",
    "And use a linear system solver to calculate $\\vec{pr}$.\n",
    "\n",
    "**2. Power-Method**\n",
    "\n",
    "Basically, re-iterating the equation (I) until it converges. \n",
    "\n",
    "\n",
    "### How Fast Google PageRank Is Calculated? [3]\n",
    "To speed up the calculations we need to take advantage of the sparse matrix calculations.  The only problem with the current formulation is that $\\mathbf{\\bar{A}}$ has a lower sparsity than the original $\\mathbf{A}$. However, we can move around pieces of the equation a little bit to skip forming this matrix. We know that:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{\\bar{A}}^T \\mathbf{\\bar{D}} \n",
    "                       &= (\\mathbf{A}^T+\\mathbf{B}^T)\\mathbf{\\bar{D}}\\\\\n",
    "                       &= \\mathbf{A}^T\\mathbf{\\bar{D}}^{-1}\n",
    "                       +\\mathbf{B}^T\\mathbf{\\bar{D}}^{-1}\n",
    "\\end{align}\n",
    "\n",
    "For the first term, multiplying by this diagonal matrix scales each column and $\\mathbf{\\bar{D}}$ and $\\mathbf{D}$ are different only in the elements whose correspondent columns were all zero in $\\mathbf{A}^T$, so we can safely replace it with $\\mathbf{D}$. Also  $\\mathbf{B}^T\\mathbf{\\bar{D}}^{-1}=\\mathbf{B}^T$ because the none zero columns of $\\mathbf{B}^T$ are all $\\vec{s}$, which add up to $1$, and therefore their correspondent element on $\\mathbf{D}$ will be $1$. Therefore,\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{\\bar{A}}^T \\mathbf{\\bar{D}} \n",
    "                       &= \\mathbf{A}^T\\mathbf{D}^{-1}\n",
    "                       +\\mathbf{B}^T,\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "and using the above equation we can re-write equation (I) and get\n",
    "\n",
    "\\begin{align}\n",
    "    \\vec{pr}_{t+1} &= \\alpha \\mathbf{A}^T\\mathbf{D}^{-1}\\vec{pr}_{t}\n",
    "                    +\\alpha\\mathbf{B}^T\\vec{pr}_{t}\n",
    "                    +(1-\\alpha)\\vec{s}. \\qquad\\mbox{(II)}\n",
    "\\end{align}\n",
    "\n",
    "This recursion has three multiplications, and the last one is a rather expensive one ($\\mathbf{B}$ is a $n\\times n$ matrix, therefore the whole multiplication will be $O(n^2)$).\n",
    "\n",
    "Being a normalized vector, we know that $\\vec{1}^T\\vec{pr}_t=1$. We can multiply the last term of Eq. $\\mbox{(II)}$ with $\\vec{1}^T\\vec{pr}_t$ and factor out $\\vec{pr}$:\n",
    "\n",
    "\\begin{align}\n",
    "    \\vec{pr} &=  \\alpha \\mathbf{A}^T\\mathbf{D}^{-1}\\vec{pr}_t\n",
    "                  +\\alpha\\mathbf{B}^T\\vec{pr}_t\n",
    "                  +(1-\\alpha)\\vec{s}\\vec{1}^T\\vec{pr}_t \\\\\n",
    "                   &= \\alpha \\mathbf{A}^T\\mathbf{D}^{-1}\\vec{pr}_t+\n",
    "                    (\\alpha\\mathbf{B}^T+\n",
    "                    (1-\\alpha)\\vec{s}\\vec{1}^T)\\vec{pr}_t.\\qquad\\mbox{(III)}\n",
    "\\end{align}\n",
    "\n",
    "Let $\\mathbf{C}$ be $\\alpha\\mathbf{B}^T+(1-\\alpha)\\vec{s}\\vec{1}^T$. Notice that $\\vec{s}\\vec{1}^T$ is a matrix with $\\vec{s}$ as its columns, and substituting the definition of $\\mathbf{B}$, the matrix $\\mathbf{C}$ will be:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{C}_{ij} &= \\begin{cases}\n",
    "                        \\vec{s}_i & \\mbox{if } r_j=0 \\\\ \n",
    "                        (1-\\alpha)\\vec{s}_i & \\mbox{else}\n",
    "                \\end{cases} \\\\  \n",
    "\\end{align}\n",
    "\n",
    "If we let $\\vec{z}$ be:\n",
    "\n",
    "\\begin{align}\n",
    "\\vec{z}_i &= \\begin{cases}\n",
    "                1 & \\mbox{if } r_i=0 \\\\ \n",
    "                (1-\\alpha) & \\mbox{else}\n",
    "                \\end{cases}  \n",
    "\\end{align}\n",
    "\n",
    "then \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{C}=\\vec{s}\\vec{z}^T\n",
    "\\end{equation}\n",
    "\n",
    "So by replacing  ($\\alpha\\mathbf{B}^T+(1-\\alpha)\\vec{s}\\vec{1}^T$) in Eq. $\\mbox{III}$ with $\\vec{s}\\vec{z}^T$, we'll get:\n",
    "\n",
    "\\begin{align}\n",
    "    \\vec{pr}_{t+1} &= \\alpha \\mathbf{A}^T\\mathbf{D}^{-1}\\vec{pr}_{t}+(\\vec{s}\\vec{z}^T)\\vec{pr}_{t}.\\qquad\\mbox{(IV)}  \n",
    "\\end{align}\n",
    "\n",
    "How does this help to improve the calculations? We'll see:\n",
    "\n",
    "**1. Solving a Linear System**\n",
    "\n",
    "Similar to befor, we can solve Eq. $\\mbox{(IV)}$ we will get:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\vec{pr}=(I-\\alpha \\mathbf{A}^T\\mathbf{D}^{-1})^{-1}(\\vec{s}\\vec{z}^T)\\vec{pr}.\n",
    "\\end{equation}\n",
    "\n",
    "Being able to re-parenthesize, $\\vec{z}^T\\vec{p}$ is just a number, so we can ignore it and renormalize $\\vec{pr}$ at the end, and solve:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\vec{pr}=(I-\\alpha \\mathbf{A}^T\\mathbf{D}^{-1})^{-1}\\vec{s}.\n",
    "\\end{equation}\n",
    "\n",
    "We almost have the same linear equation system that we had before, except for one big improvement, we replaced the less-sparse $\\mathbf{\\bar{A}}$ with $\\mathbf{A}$.\n",
    "\n",
    "**2. Power Method**\n",
    "\n",
    "We can apply one last smart modification to Eq. $\\mbox{(IV)}$, if we change the parenthesizing of the last multiplication ([remember the famous dynamic programming algorithm](https://en.wikipedia.org/wiki/Matrix_chain_multiplication)?), and also define $\\mathbf{W}=\\alpha\\mathbf{A}^T\\mathbf{D}^{-1}$, we will have:\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{pr}_{t+1} = \\mathbf{W}\\vec{pr}_{t}+\n",
    "                \\vec{s}(\\vec{z}^T\\vec{pr}_{t})\n",
    "\\end{equation}\n",
    "\n",
    "Therefore, the complexity decreased to $O(n)$, and the whole recursion will be $O(n)\\times \\#iterations$. The rate of convergence is another thing, which we ignore here, and depends on the value of the second eigen value ($\\lambda_2$) of the modified transition matrix, which is defined as:\n",
    "\\begin{equation}\n",
    "\\mathbf{T}=\\alpha\\mathbf{A}^T\\mathbf{D}^{-1}+\\vec{s}\\vec{z}^T\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "[1] [Daniel A. Spielman](https://en.wikipedia.org/wiki/Daniel_Spielman), Graphs and Networks Lecture Notes, [Lecture 11: Cutting Graphs, Personal PageRank and Spilling Paint](http://www.cs.yale.edu/homes/spielman/462/lect11-13.pdf), 2013. \n",
    "\n",
    "[2] [Daniel A. Spielman](https://en.wikipedia.org/wiki/Daniel_Spielman), Spectral Graph Theory Lecture Notes, [Lecture 10: Random Walks on Graphs](http://www.cs.yale.edu/homes/spielman/561/lect10-18.pdf), 2018\n",
    "\n",
    "[3] [Cleve Moler](https://en.wikipedia.org/wiki/Cleve_Moler), *Experiments with MATLAB*, [Chapter 7:\n",
    "Google PageRank](https://www.mathworks.com/content/dam/mathworks/mathworks-dot-com/moler/exm/chapters/pagerank.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2:2: E228 missing whitespace around modulo operator\n",
      "13:1: E402 module level import not at top of file\n",
      "15:1: E402 module level import not at top of file\n",
      "16:1: E402 module level import not at top of file\n",
      "17:1: E402 module level import not at top of file\n",
      "18:1: E402 module level import not at top of file\n",
      "62:5: E741 ambiguous variable name 'I'\n",
      "122:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../fast_pagerank/pagerank.py\n",
    "\"\"\"Two fast implementations of PageRank:\n",
    "    An exact solution using a sparse linear system solver,\n",
    "    and an a power method approximation.\n",
    "    Both solutions are taking full advantage of sparse matrix calculations.\n",
    "\n",
    "    [Reference]:\n",
    "    Cleve Moler. 2011. Experiments with MATLAB (Electronic ed.).\n",
    "    MathWorks, Inc.\n",
    "\"\"\"\n",
    "# uncomment\n",
    "from __future__ import division\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.sparse as sprs\n",
    "import scipy.spatial\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "__author__ = \"Armin Sajadi\"\n",
    "__copyright__ = \"Copyright 2015, The Wikisim Project\"\n",
    "__email__ = \"asajadi@gmail.com\"\n",
    "\n",
    "\n",
    "def pagerank(A, p=0.85,\n",
    "             personalize=None, reverse=False):\n",
    "    \"\"\" Calculates PageRank given a csr graph\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "\n",
    "    G: a csr graph.\n",
    "    p: damping factor\n",
    "    personlize: if not None, should be an array with the size of the nodes\n",
    "                containing probability distributions.\n",
    "                It will be normalized automatically\n",
    "    reverse: If true, returns the reversed-PageRank\n",
    "\n",
    "    outputs\n",
    "    -------\n",
    "\n",
    "    PageRank Scores for the nodes\n",
    "\n",
    "    \"\"\"\n",
    "    # In Moler's algorithm, $A_{ij}$ represents the existences of an edge\n",
    "    # from node $j$ to $i$, while we have assumed the opposite!\n",
    "    if reverse:\n",
    "        A = A.T\n",
    "\n",
    "    n, _ = A.shape\n",
    "    r = sp.asarray(A.sum(axis=1)).reshape(-1)\n",
    "\n",
    "    k = r.nonzero()[0]\n",
    "\n",
    "    D_1 = sprs.csr_matrix((1 / r[k], (k, k)), shape=(n, n))\n",
    "\n",
    "    if personalize is None:\n",
    "        personalize = sp.ones(n)\n",
    "    personalize = personalize.reshape(n, 1)\n",
    "    s = (personalize / personalize.sum()) * n\n",
    "\n",
    "    I = sprs.eye(n)\n",
    "    x = sprs.linalg.spsolve((I - p * A.T @ D_1), s)\n",
    "\n",
    "    x = x / x.sum()\n",
    "    return x\n",
    "\n",
    "\n",
    "def pagerank_power(A, p=0.85, max_iter=100,\n",
    "                   tol=1e-06, personalize=None, reverse=False):\n",
    "    \"\"\" Calculates PageRank given a csr graph\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    A: a csr graph.\n",
    "    p: damping factor\n",
    "    max_iter: maximum number of iterations\n",
    "    personlize: if not None, should be an array with the size of the nodes\n",
    "                containing probability distributions.\n",
    "                It will be normalized automatically.\n",
    "    reverse: If true, returns the reversed-PageRank\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    PageRank Scores for the nodes\n",
    "\n",
    "    \"\"\"\n",
    "    # In Moler's algorithm, $G_{ij}$ represents the existences of an edge\n",
    "    # from node $j$ to $i$, while we have assumed the opposite!\n",
    "    if reverse:\n",
    "        A = A.T\n",
    "\n",
    "    n, _ = A.shape\n",
    "    r = sp.asarray(A.sum(axis=1)).reshape(-1)\n",
    "\n",
    "    k = r.nonzero()[0]\n",
    "\n",
    "    D_1 = sprs.csr_matrix((1 / r[k], (k, k)), shape=(n, n))\n",
    "\n",
    "    if personalize is None:\n",
    "        personalize = sp.ones(n)\n",
    "    personalize = personalize.reshape(n, 1)\n",
    "    s = (personalize / personalize.sum()) * n\n",
    "\n",
    "    z_T = (((1 - p) * (r != 0) + (r == 0)) / n)[sp.newaxis, :]\n",
    "    W = p * A.T @ D_1\n",
    "\n",
    "    x = s\n",
    "    oldx = sp.zeros((n, 1))\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    while sp.linalg.norm(x - oldx) > tol:\n",
    "        oldx = x\n",
    "        x = W @ x + s @ (z_T @ x)\n",
    "        iteration += 1\n",
    "        if iteration >= max_iter:\n",
    "            break\n",
    "    x = x / sum(x)\n",
    "\n",
    "    return x.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../test/pagerank_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../test/pagerank_test.py\n",
    "import os\n",
    "import sys\n",
    "import scipy as sp\n",
    "import scipy.sparse as sparse\n",
    "from numpy.testing import assert_allclose\n",
    "import unittest\n",
    "\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    os.path.abspath(\n",
    "        os.path.join(\n",
    "            os.path.dirname(__file__),\n",
    "            '..')))\n",
    "\n",
    "from fast_pagerank.pagerank import pagerank_power\n",
    "from fast_pagerank.pagerank import pagerank\n",
    "\n",
    "\n",
    "class TestMolerPageRank(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # ---G1---\n",
    "        n1 = 5\n",
    "        rows1 = [0, 1, 2, 2, 2, 3, 3, 4, 4, 4]\n",
    "        cols1 = [1, 2, 1, 3, 4, 0, 2, 0, 2, 3]\n",
    "        data1 = [\n",
    "            0.4923, 0.0999, 0.2132, 0.0178, 0.5694,\n",
    "            0.0406, 0.2047, 0.861, 0.3849, 0.4829]\n",
    "\n",
    "        self.p1 = 0.83\n",
    "        self.personalize1 = sp.array([0.6005, 0.1221, 0.2542, 0.4778, 0.4275])\n",
    "        self.G1 = sparse.csr_matrix((data1, (rows1, cols1)), shape=(n1, n1))\n",
    "        self.pr1 = sp.array([0.1592, 0.2114, 0.3085, 0.1, 0.2208])\n",
    "\n",
    "        # ---G2---\n",
    "        n2 = 10\n",
    "        rows2 = [2, 2, 4, 5, 5, 5, 6, 6, 9, 9]\n",
    "        cols2 = [4, 5, 5, 3, 4, 9, 1, 2, 2, 4]\n",
    "        data2 = [\n",
    "            0.4565, 0.2861, 0.573, 0.0025, 0.4829,\n",
    "            0.3866, 0.3041, 0.3407, 0.2653, 0.8079]\n",
    "        self.G2 = sparse.csr_matrix((data2, (rows2, cols2)), shape=(n2, n2))\n",
    "        self.personalize2 = sp.array([0.8887, 0.6491, 0.7843, 0.7103, 0.7428,\n",
    "                                      0.6632, 0.7351, 0.3006, 0.8722, 0.1652])\n",
    "        self.p2 = 0.92\n",
    "        self.pr2 = sp.array([0.0234, 0.0255, 0.0629, 0.0196, 0.3303,\n",
    "                             0.3436, 0.0194, 0.0079, 0.023, 0.1445])\n",
    "\n",
    "        # ---G3---\n",
    "        n3 = 5\n",
    "        rows3 = [2]\n",
    "        cols3 = [4]\n",
    "        data3 = [0.5441]\n",
    "        self.G3 = sparse.csr_matrix((data3, (rows3, cols3)), shape=(n3, n3))\n",
    "\n",
    "        self.personalize3 = sp.array([0.0884, 0.2797, 0.3093, 0.5533, 0.985])\n",
    "        self.p3 = 0.81\n",
    "        self.pr3 = sp.array([0.0358, 0.1134, 0.1254, 0.2244, 0.501])\n",
    "\n",
    "        # ---G4---\n",
    "        n4 = 5\n",
    "        rows4 = []\n",
    "        cols4 = []\n",
    "        data4 = []\n",
    "        self.G4 = sparse.csr_matrix((data4, (rows4, cols4)), shape=(n4, n4))\n",
    "\n",
    "        self.personalize4 = sp.array([0.2534, 0.8945, 0.9562, 0.056, 0.9439])\n",
    "        self.p4 = 0.70\n",
    "        self.pr4 = sp.array([0.0816, 0.2882, 0.3081, 0.018, 0.3041])\n",
    "\n",
    "        # ---G5---\n",
    "        n5 = 0\n",
    "        rows5 = []\n",
    "        cols5 = []\n",
    "        data5 = []\n",
    "        self.G5 = sparse.csr_matrix((data5, (rows5, cols5)), shape=(n5, n5))\n",
    "\n",
    "        self.personalize5 = sp.array([])\n",
    "        self.p5 = 0.70\n",
    "        self.pr5 = sp.array([])\n",
    "\n",
    "    def test_pagerank_1(self):\n",
    "        calculated_pagerank = pagerank(self.G1, p=self.p1,\n",
    "                                       personalize=self.personalize1)\n",
    "        assert_allclose(calculated_pagerank, self.pr1, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_pagerank_2(self):\n",
    "\n",
    "        calculated_pagerank = pagerank(self.G2, p=self.p2,\n",
    "                                       personalize=self.personalize2)\n",
    "        assert_allclose(calculated_pagerank, self.pr2, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_single_edge(self):\n",
    "        calculated_pagerank = pagerank(self.G3, p=self.p3,\n",
    "                                       personalize=self.personalize3)\n",
    "        assert_allclose(calculated_pagerank, self.pr3, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_zero_edge(self):\n",
    "        calculated_pagerank = pagerank(self.G4, p=self.p4,\n",
    "                                       personalize=self.personalize4)\n",
    "        assert_allclose(calculated_pagerank, self.pr4, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_empty_graph(self):\n",
    "        calculated_pagerank = pagerank(self.G5, p=self.p5,\n",
    "                                       personalize=self.personalize5)\n",
    "        self.assertEqual(calculated_pagerank.size, 0)\n",
    "\n",
    "    def test_power_pagerank_1(self):\n",
    "        calculated_pagerank = pagerank_power(self.G1, p=self.p1,\n",
    "                                             personalize=self.personalize1)\n",
    "        assert_allclose(calculated_pagerank, self.pr1, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_power_pagerank_2(self):\n",
    "\n",
    "        calculated_pagerank = pagerank_power(self.G2, p=self.p2,\n",
    "                                             personalize=self.personalize2)\n",
    "        assert_allclose(calculated_pagerank, self.pr2, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_power_single_edge(self):\n",
    "        calculated_pagerank = pagerank_power(self.G3, p=self.p3,\n",
    "                                             personalize=self.personalize3)\n",
    "        assert_allclose(calculated_pagerank, self.pr3, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_power_zero_edge(self):\n",
    "        calculated_pagerank = pagerank_power(self.G4, p=self.p4,\n",
    "                                             personalize=self.personalize4)\n",
    "        assert_allclose(calculated_pagerank, self.pr4, rtol=0, atol=1e-04)\n",
    "\n",
    "    def test_power_empty_graph(self):\n",
    "        calculated_pagerank = pagerank_power(self.G5, p=self.p5,\n",
    "                                             personalize=self.personalize5)\n",
    "        self.assertEqual(calculated_pagerank.size, 0)\n",
    "\n",
    "\n",
    "#             assert_array_almost_equal(Ynx,  Yml, decimal = 5)\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python  ../test/pagerank_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "To avoid the clutter, we only visualize the fastest method from each implementation, that is: \n",
    "\n",
    "- `networkx.pagerank_scipy`\n",
    "- Latest implementation of  `iGraph.personalized_pagerank` (PRPACK)\n",
    "- Our `pagerank_power` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:1: E402 module level import not at top of file\n",
      "16:1: E402 module level import not at top of file\n"
     ]
    }
   ],
   "source": [
    "''' Calcualate PageRank on several random graphs.\n",
    "I had to comment out the slower functions (mainly the first two Networkx),\n",
    "because they were almost crashing on large graphs.\n",
    "'''\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import igraph\n",
    "import networkx as nx\n",
    "sys.path.insert(0, '..')\n",
    "from fast_pagerank.pagerank import pagerank\n",
    "from fast_pagerank.pagerank import pagerank_power\n",
    "\n",
    "\n",
    "def get_random_graph(\n",
    "        min_size=100,\n",
    "        max_size=1000,\n",
    "        min_density=0.1,\n",
    "        max_density=0.8):\n",
    "    ''' Creates a random graph and a teleport vector and output them\n",
    "        in different formats for different algorithms\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "\n",
    "    min_size and max_size: The size of the graph will be a random number\n",
    "        in the range of (min_size, max_size)\n",
    "    min_sparsity and max_sparsity: The sparcity of the graph\n",
    "        will be a random number in the range of (min_sparsity, max_sparsity)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    nxG: A random Graph for NetworkX\n",
    "    A: The equivallent csr Adjacency matrix, for our PageRank\n",
    "    iG: The equivallent iGraph\n",
    "    personalize_vector: Personalization probabily vector\n",
    "    personalize_dict: Personalization probabily vector,\n",
    "                    in the form of a dictionary for NetworkX\n",
    "\n",
    "    '''\n",
    "    G_size = random.randint(min_size, max_size)\n",
    "    p = random.uniform(min_density, max_density)\n",
    "\n",
    "    A = sp.sparse.random(G_size, G_size, p, format='csr')\n",
    "    nxG = nx.from_scipy_sparse_matrix(A, create_using=nx.DiGraph())\n",
    "\n",
    "    iG = igraph.Graph(list(nxG.edges()), directed=True)\n",
    "    iG.es['weight'] = A.data\n",
    "\n",
    "    personalize_vector = sp.random.random(G_size)\n",
    "    personalize_dict = dict(enumerate(personalize_vector.reshape(-1)))\n",
    "    return A, nxG, iG, personalize_vector, personalize_dict\n",
    "\n",
    "\n",
    "n = 5\n",
    "number_of_graphs = 20\n",
    "\n",
    "node_size_vector = sp.zeros(number_of_graphs)\n",
    "edge_size_vector = sp.zeros(number_of_graphs)\n",
    "# netx_pagerank_times = sp.zeros(number_of_graphs)\n",
    "# netx_pagerank_times_numpy = sp.zeros(number_of_graphs)\n",
    "netx_pagerank_times_scipy = sp.zeros(number_of_graphs)\n",
    "ig_pagerank_times = sp.zeros(number_of_graphs)\n",
    "# pagerank_times = sp.zeros(number_of_graphs)\n",
    "pagerank_times_power = sp.zeros(number_of_graphs)\n",
    "\n",
    "damping_factor = 0.85\n",
    "tol = 1e-6\n",
    "\n",
    "\n",
    "for i in range(number_of_graphs):\n",
    "    A, nxG, iG, personalize_vector, personalize_dict = get_random_graph()\n",
    "    node_size_vector[i] = A.shape[0]\n",
    "    edge_size_vector[i] = A.count_nonzero()\n",
    "\n",
    "#     Networkx (the first two are commented out, because\n",
    "#     they are too slow and almost crash):\n",
    "\n",
    "#     netx_pagerank_times[i] = timeit.timeit(\n",
    "#         lambda: nx.pagerank(nxG, alpha=damping_factor, tol=tol),\n",
    "#         number=n) / n\n",
    "#     netx_pagerank_times_numpy[i] = timeit.timeit(\n",
    "#         lambda: nx.pagerank_numpy(nxG, alpha=damping_factor),\n",
    "#         number=n) / n\n",
    "    netx_pagerank_times_scipy[i] = timeit.timeit(\n",
    "        lambda: nx.pagerank_scipy(nxG, alpha=damping_factor, tol=tol),\n",
    "        number=n) / n\n",
    "\n",
    "#     iGraph, only \"prpack\", which is their latest version.\n",
    "    ig_pagerank_times[i] = timeit.timeit(\n",
    "        lambda: iG.personalized_pagerank(directed=True,\n",
    "                                         damping=damping_factor,\n",
    "                                         weights=iG.es['weight'],\n",
    "                                         implementation=\"prpack\"),\n",
    "        number=n) / n\n",
    "\n",
    "#     My implementations: The first one is pretty good, but\n",
    "#     I'm just comparing the fastest ones here.\n",
    "\n",
    "#     pagerank_times[i] = timeit.timeit(\n",
    "#         lambda: pagerank(A, p=damping_factor),\n",
    "#         number=n) / n\n",
    "    pagerank_times_power[i] = timeit.timeit(\n",
    "        lambda: pagerank_power(A, p=damping_factor, tol=tol),\n",
    "        number=n) / n\n",
    "\n",
    "\n",
    "argsort = edge_size_vector.argsort()\n",
    "\n",
    "edge_size_vector_sorted = edge_size_vector[argsort]\n",
    "node_size_vector_sorted = node_size_vector[argsort]\n",
    "\n",
    "# netx_pagerank_times_sorted = netx_pagerank_times[argsort]\n",
    "# netx_pagerank_times_numpy_sorted = netx_pagerank_times_numpy[argsort]\n",
    "netx_pagerank_times_scipy_sorted = netx_pagerank_times_scipy[argsort]\n",
    "\n",
    "ig_pagerank_times_sorted = ig_pagerank_times[argsort]\n",
    "\n",
    "# pagerank_times_sorted = pagerank_times[argsort]\n",
    "pagerank_times_power_sorted = pagerank_times_power[argsort]\n",
    "\n",
    "comparison_table = pd.DataFrame(list(zip(node_size_vector_sorted,\n",
    "                                         edge_size_vector_sorted,\n",
    "                                         netx_pagerank_times_scipy_sorted,\n",
    "                                         ig_pagerank_times_sorted,\n",
    "                                         pagerank_times_power_sorted)),\n",
    "                                columns=['Nodes', 'Edges',\n",
    "                                         'pagerank_times_power_sorted',\n",
    "                                         'iGraph_PageRank_ARPACK',\n",
    "                                         '(fast) pagerank_Power']).\\\n",
    "                    astype({'Nodes': 'int32', 'Edges': 'int32'})\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2: E999 SyntaxError: invalid syntax\n",
      "6:4: E225 missing whitespace around operator\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.ioff()\n",
    "fig=plt.figure(num=None, figsize=(7, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "\n",
    "# plt.plot(edge_size_vector_sorted, netx_pagerank_times_sorted,\n",
    "#          'o-', ms=8, lw=2, alpha=0.7, color='cyan',\n",
    "#          label='networkx.PageRank')\n",
    "# plt.plot(edge_size_vector_sorted, netx_pagerank_times_numpy_sorted,\n",
    "#          'v-', ms=8, lw=2, alpha=0.7, color='magenta',\n",
    "#          label='networkx.PageRank_numpy')\n",
    "\n",
    "plt.plot(edge_size_vector_sorted, netx_pagerank_times_scipy_sorted,\n",
    "         'P-', ms=8, lw=2, alpha=0.7, color='blue',\n",
    "         label='networkx.PageRank_scipy')\n",
    "\n",
    "plt.plot(edge_size_vector_sorted, ig_pagerank_times_sorted,\n",
    "         'x-', ms=8, lw=2, alpha=0.7, color='black',\n",
    "         label='iGraph_PageRank_ARPACK')\n",
    "\n",
    "# plt.plot(edge_size_vector_sorted, pagerank_times,\n",
    "#          '*-', ms=8, lw=2, alpha=0.7, color='red',\n",
    "#          label='(fast) pagerank')\n",
    "plt.plot(edge_size_vector_sorted, pagerank_times_power,\n",
    "         '^-', ms=8, lw=2, alpha=0.7, color='green',\n",
    "         label='(fast) pagerank_Power')\n",
    "\n",
    "\n",
    "plt.xlabel('Number of the edges')\n",
    "plt.ylabel('Time (Seconds)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=2)\n",
    "plt.savefig('pagerank.png')\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4:31: W291 trailing whitespace\n",
      "5:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "display(comparison_table)\n",
    "Image(filename='pagerank.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (general)",
   "language": "python",
   "name": "general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
